{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wake word processing\n",
    "\n",
    "This notebook is to train a wake word model using tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "for data preprocessing we use the `python_speech_features` package for simplicity as we just have extract the mfcc feature and that package is as simple as posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!virtualenv env\n",
    "!source env/bin/activate\n",
    "!pip install -r requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This proccess is to make dataset.\n",
    "The dataset consist of wake word and non wake word. In each audio file only have one class, either wake word or non wake word.\n",
    "The audio itself, is then extracted using mfcc feature extraction that loaded from python_speech_features module. In this block we create dataset with various length of mfcc features, thus after this process it is required to apply some padding so the input data would be in the same shape. As for the target or label we make one hot encodeing so that the array of [0,1] would represent a non wake word uttarance and [1,0] as a wake word uttarance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "ww = \"\" # wake word audio directory\n",
    "nww = \"\" # non wake word audio directory\n",
    "\n",
    "X = []\n",
    "Y = []   # ww = [1,0] , nww = [0,1]\n",
    "\n",
    "maxshapeX = 0\n",
    "\n",
    "for x in glob.glob(ww+\"*.wav\"):\n",
    "    sr, frame = wav.read(x)\n",
    "    feat = mfcc(frame, sr) \n",
    "    if feat.shape[0] > 1000:\n",
    "        continue\n",
    "    if feat.shape[0] > maxshapeX:\n",
    "        maxshapeX = feat.shape[0]\n",
    "        print(maxshapeX)\n",
    "    X.append( feat )\n",
    "    Y.append( np.array( [1, 0] ) )\n",
    "    \n",
    "for x in glob.glob(nww+\"*.wav\"):\n",
    "    sr, frame = wav.read(x)\n",
    "    feat = mfcc(frame, sr) \n",
    "    if feat.shape[0] > 1000:\n",
    "        continue\n",
    "    if feat.shape[0] > maxshapeX:\n",
    "        maxshapeX = feat.shape[0]\n",
    "        print(maxshapeX)\n",
    "    X.append( feat )\n",
    "    Y.append( np.array( [0, 1] ) )\n",
    "    \n",
    "Y = np.array(Y)\n",
    "\n",
    "print(maxshapeX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_along_axis(array: np.ndarray, target_length, axis=0):\n",
    "\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "    axis_nb = len(array.shape)\n",
    "\n",
    "    if pad_size < 0:\n",
    "        return array\n",
    "\n",
    "    npad = [(0, 0) for x in range(axis_nb)]\n",
    "    npad[axis] = (0, pad_size)\n",
    "\n",
    "    b = np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "    return b\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = pad_along_axis(X[i], maxshapeX, 0)\n",
    "\n",
    "X = np.array(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "np.save('X', X)\n",
    "np.save('Y', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Activation, BatchNormalization, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout  \n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_model_cnn(n_timesteps, n_dim, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu',data_format=\"channels_last\", input_shape=(n_timesteps,n_dim)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "X = np.load('X.npy')\n",
    "Y = np.load('Y.npy')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=19)\n",
    "\n",
    "n_dim = X_train.shape[2]  \n",
    "n_classes = y_train.shape[1] \n",
    "n_timesteps = X_train.shape[1]\n",
    "model_cnn = create_model_cnn(n_timesteps, n_dim, n_classes)\n",
    "print(\"CNN\")\n",
    "hist = model_cnn.fit(X_train, y_train, epochs=epochs, batch_size=4, verbose=2)\n",
    "model_cnn.save('model-cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test with a new data\")\n",
    "print(model_cnn.evaluate(x=X_test, y=y_test))\n",
    "# model_cnn.save('model-cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "prob = []\n",
    "\n",
    "for x in X_test :\n",
    "    x = np.reshape( x, (1,846,13) )\n",
    "    pred = model_cnn.predict(x)\n",
    "    idx = np.argmax(pred)\n",
    "    prob.append(pred[0][idx])\n",
    "    kelas = \"Wakeword\" if idx == 0 else \"Not wake word\"\n",
    "    print(f\"Kelas {kelas} dengan probability {pred[0][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the fly test\n",
    "This is the wraper to e2e process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import numpy as np\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def pad_along_axis(array: np.ndarray, target_length, axis=0):\n",
    "\n",
    "    pad_size = target_length - array.shape[axis]\n",
    "    axis_nb = len(array.shape)\n",
    "\n",
    "    if pad_size < 0:\n",
    "        return array\n",
    "\n",
    "    npad = [(0, 0) for x in range(axis_nb)]\n",
    "    npad[axis] = (0, pad_size)\n",
    "\n",
    "    b = np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
    "\n",
    "    return b\n",
    "\n",
    "def load_h5model(path):\n",
    "    return load_model(path)\n",
    "    \n",
    "\n",
    "    \n",
    "model = load_h5model(\"model-cnn.h5\")\n",
    "x = \"\" # example audio\n",
    "\n",
    "sr, frame = wav.read(x)\n",
    "x = mfcc(frame, sr)\n",
    "\n",
    "if x.shape != (846, 13):\n",
    "    # Padding\n",
    "    if x.shape[0] < 846:\n",
    "        x = pad_along_axis(x, 846,0)\n",
    "    elif x.shape[0] > 846:\n",
    "        x = x[:846,:]\n",
    "\n",
    "x = np.reshape( x, (1,846,13) )\n",
    "pred = model.predict(x)\n",
    "idx = np.argmax(pred)\n",
    "kelas = \"Wakeword\" if idx == 0 else \"Not wake word\"\n",
    "hasil = {\n",
    "    'prob' : pred[0][idx],\n",
    "    'label' : kelas\n",
    "}\n",
    "hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model into tensorlite model using command line\n",
    "\n",
    "This command line is used to convert the model into a tensorflow lite model. To use this model using tflite config please refer [here](https://github.com/juunnn/wakeword/tree/engine/engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert --keras_model_file model-cnn.h5 --output_file model.tflite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
